{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Your AI Agent with MCPs using SGLang, Pydantic AI, and AMD MI300X GPU\n",
    "\n",
    "Welcome to this hands-on workshop! Throughout this tutorial, we'll leverage AMD GPUs and **Model Context Protocol (MCP)** ,an open standard for exposing LLM tools via API, to deploy powerful language models like Qwen3-30B. Key components:\n",
    "- üñ•Ô∏è **SGLang** for GPU-optimized inference\n",
    "- üõ†Ô∏è **Pydantic-AI** for agent/tool management\n",
    "- üîå **MCP Servers** for pre-built tool integration\n",
    "\n",
    "You'll learn how to set up your environment, deploy large language models like Qwen3-30B, connect them to real-world tools using MCP, and build a conversational agent capable of reasoning and taking actions\n",
    "\n",
    "By the end of this workshop, you‚Äôll have built an AI-powered assistant agent that can find a place to stay based on your preferences like location, budget, and travel dates.\n",
    "\n",
    "Let‚Äôs dive in!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Step 1: Launching SGLang Server on AMD GPUs](#step1)\n",
    "- [Step 2: Installing Dependencies](#step2)\n",
    "- [Step 3: Create a simple instance of Pydantic-AI Agent](#step3)\n",
    "- [Step 4: Write a Date/Time Tool for your Agent](#step4)\n",
    "- [Step 5: Replace your Date/Time Tool with a MCP Server](#step5)\n",
    "- [Step 6: Turn your Agent into a trip planner](#step6)\n",
    "- [Step 7: Challenge](#step7)\n",
    "\n",
    "<a id=\"step1\"></a>\n",
    "\n",
    "## Step 1: Launch a SGLang Server\n",
    "\n",
    "In this workshop we are going to use [SGLang](https://github.com/sgl-project/sglang) as our inference serving engine. SGLang provides many benefits such as fast model execution, extensive list of supported models, easy to use, and best of all it's open-source. \n",
    "\n",
    "### Deploy Qwen3-30B Model with SGLang (~2mins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to start a SGLang server and create an OpenAI-compatible endpoint for your LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sglang.utils import launch_server_cmd\n",
    "os.environ[\"SGLANG_USE_AITER\"] = \"1\"\n",
    "server_process, port = launch_server_cmd(\n",
    "    \"python3 -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B-Instruct-2507 --tool-call-parser qwen25 --host 0.0.0.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait till you see \"The server is fired up and ready to roll!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = f\"http://localhost:{port}/v1\"\n",
    "\n",
    "os.environ[\"BASE_URL\"]    = BASE_URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"abc-123\"   \n",
    "\n",
    "print(\"Config set:\", BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify your model is available at the `BASE_URL` we just set by running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl $BASE_URL/models -H \"Authorization: Bearer $OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you now just launched a powerful server that can serve any incoming request and allowing you to build amazing applications. Wasn't that easy?üéâ \n",
    "\n",
    "<a id=\"step2\"></a>\n",
    "\n",
    "## Step 2: Installing Dependencies\n",
    "\n",
    "We are going to use `Pydantic AI`, `DuckDuckGo`, and `MCP`, let's install these dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic_ai mcp httpx duckduckgo_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"step3\"></a>\n",
    "\n",
    "## Step 3: Create a simple instance of Pydantic-AI Agent\n",
    "\n",
    "Let's start by creating a custom OpenAI Compatible endpoint for our agent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "provider = OpenAIProvider(\n",
    "    base_url=os.environ[\"BASE_URL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "agent_model = OpenAIModel(\"Qwen/Qwen3-30B-A3B-Instruct-2507\", provider=provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating an instance the `Agent` class from `pydantic_ai`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    model=agent_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to test the agent. `pydantic_ai` provides multiple ways to run `Agent`. You can learn more about it [here](https://ai.pydantic.dev/agents/#running-agents).\n",
    "\n",
    "In this workshop, we are running in `async` mode. We are going to define a helper function that allows us to quickly test our agent throughout this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_async(prompt: str) -> str:\n",
    "    async with agent:\n",
    "        result = await agent.run(prompt)\n",
    "        return result.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the agent by calling this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_async(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! now that we have the basics of creating an agent instance, and connecting it to the model we started serving with SGLang earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "\n",
    "## Step 4: Write a Date/Time Tool for Your Agent\n",
    "\n",
    "LLMs naturally rely on their training data to respond to your prompts. Therefore, the agent we just defined fails to answer a factual question that falls outside of it's training knowledge. Let's show this with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_async(\"What‚Äôs the date today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is no surprise that the model failed to answer this question. Now, it's time to power-up your LLM by providing `agent` a function that can get the current date. The process of an LLM triggering a function call is commonly referred to as `Tool Calling` or `Function Calling`. In this workshop we are going to take advantage of `pydantic-ai`'s agent `tools` to provide our agent appropriate tools. First, we need to define a custom tool. Below is how we can define a tool in this framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pydantic_ai import Tool          \n",
    "@Tool\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"Return the current date/time as an ISO-formatted string.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to provide this tool to our Agent, as this will notify the LLM about the existence of such a tool we just definied. This is simply done by just providing the function signiture of the tool we just defined to our agent constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=agent_model,\n",
    "    tools=[get_current_date],\n",
    "    system_prompt = (\n",
    "        \"You have access to:\\n\"\n",
    "        \"   1. get_current_time(params: dict)\\n\"\n",
    "        \"Use this tool for date/time questions.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_async(\"What‚Äôs the date today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done on building an agent with access to real-time data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id=\"step5\"></a>\n",
    "\n",
    "## Step 5: Replace Your Date/time Tool with a MCP server\n",
    "\n",
    "Now that we learned how to create a custom tool and provide the agent access to this tool. Let's now explore a trendy topic of [Model Context Protocol](https://modelcontextprotocol.io/introduction). We are going to explore how we can replace our custom tool with a simple MCP server that can serve our agent and provide similar information.\n",
    "\n",
    "**Why MCP?** MCP servers provide:\n",
    "- ‚úÖ Standardized API interfaces\n",
    "- üîÑ Reusable across projects\n",
    "- üì¶ Pre-built functionality\n",
    "\n",
    "Let's replace our custom time tool with an official MCP time server:\n",
    "\n",
    "### Installing Time MCP Server\n",
    "\n",
    "We are going to start by installing this MCP server:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mcp-server-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our time_server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "time_server = MCPServerStdio(\n",
    "    \"python\",\n",
    "    args=[\n",
    "        \"-m\", \"mcp_server_time\",\n",
    "        \"--local-timezone=America/New_York\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's modify our agent to remove our previously defined tool, and add this MCP server instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=agent_model,\n",
    "    mcp_servers=[time_server],\n",
    "    system_prompt = (\n",
    "        \"You are a helpful agent and you have access to this tool:\\n\"\n",
    "        \"   get_current_time(params: dict)\\n\"\n",
    "        \"When the user asks for the current date or time, call get_current_time.\\n\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Great, let's see if the agent can use the MCP to give us the correct time now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_async(\"What‚Äôs the date today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Turn your agents for travel planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
    "!sudo apt-get install -y nodejs\n",
    "!node -v && npm -v && npx -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tadaa! Now you have officially used MCP servers to power-up your AI agents. In the next section we show how you can your turn many ideas into real working projects by using free MCP servers available today.\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"step6\"></a>\n",
    "\n",
    "## Step 6: Turn your agent to a travel planner\n",
    "\n",
    "As we experience in the last section, MCP servers are really easy to use and they provide a standard way of providing LLMs the tools we need. There are already thousands of MCP servers available for us to use. There are some MCP trackers that you can always use to find out about available servers. Here are some for your reference:\n",
    "- https://github.com/modelcontextprotocol/servers\n",
    "- https://mcp.so/\n",
    "\n",
    "We are going to use npx to launch out next server. Therefore, let's install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Node.js 20 via NodeSource\n",
    "!curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
    "!apt install -y nodejs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify `npm` and `npx` installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!node -v && npm -v && npx --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === One cell to rule them all (multi-agent trip planner) ===\n",
    "# Copy-paste into a Jupyter/Colab notebook and run.\n",
    "\n",
    "import sys, os, subprocess, pkgutil, pathlib, textwrap, asyncio, re, json, math\n",
    "from typing import Any, Dict, List, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 0) Basics + ensure deps ------------------------------------------------------\n",
    "PY = sys.executable\n",
    "ROOT = pathlib.Path.cwd() / \"mcp_nb\"\n",
    "ROOT.mkdir(exist_ok=True)\n",
    "BASE_ENV = os.environ.copy()\n",
    "BASE_ENV[\"PYTHONUNBUFFERED\"] = \"1\"\n",
    "\n",
    "def ensure_pkgs():\n",
    "    to_check = [\n",
    "        (\"mcp\", \"mcp\"),\n",
    "        (\"pydantic_ai\", \"pydantic-ai\"),\n",
    "        (\"duckduckgo_search\", \"duckduckgo-search\"),\n",
    "        (\"httpx\", \"httpx\"),\n",
    "        (\"tzdata\", \"tzdata\"),\n",
    "    ]\n",
    "    missing = []\n",
    "    for mod, pipname in to_check:\n",
    "        if not any(m == mod or m.startswith(mod + \".\") for m in sys.modules):\n",
    "            if not pkgutil.find_loader(mod):\n",
    "                missing.append(pipname)\n",
    "    if missing:\n",
    "        print(\"Installing:\", \", \".join(sorted(set(missing))))\n",
    "        subprocess.check_call([PY, \"-m\", \"pip\", \"install\", \"-q\", *sorted(set(missing))])\n",
    "\n",
    "ensure_pkgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pkgutil, subprocess, pathlib, textwrap, asyncio, re, json, math\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 0) Basics + ensure deps\n",
    "PY = sys.executable\n",
    "ROOT = pathlib.Path.cwd() / \"mcp_nb\"\n",
    "ROOT.mkdir(exist_ok=True)\n",
    "BASE_ENV = os.environ.copy()\n",
    "BASE_ENV[\"PYTHONUNBUFFERED\"] = \"1\"\n",
    "\n",
    "def ensure_pkgs():\n",
    "    to_check = [\n",
    "        (\"mcp\", \"mcp\"),\n",
    "        (\"pydantic_ai\", \"pydantic-ai\"),\n",
    "        (\"duckduckgo_search\", \"duckduckgo-search\"),\n",
    "        (\"httpx\", \"httpx\"),\n",
    "        (\"tzdata\", \"tzdata\"),\n",
    "        (\"openai\", \"openai\"),          # for OpenAIModel\n",
    "        (\"anthropic\", \"anthropic\"),    # optional AnthropicModel\n",
    "        (\"nest_asyncio\", \"nest-asyncio\"),\n",
    "    ]\n",
    "    missing = []\n",
    "    for mod, pipname in to_check:\n",
    "        if not any(m == mod or m.startswith(mod + \".\") for m in sys.modules):\n",
    "            if not pkgutil.find_loader(mod):\n",
    "                missing.append(pipname)\n",
    "    if missing:\n",
    "        print(\"Installing:\", \", \".join(sorted(set(missing))))\n",
    "        subprocess.check_call([PY, \"-m\", \"pip\", \"install\", \"-q\", *sorted(set(missing))])\n",
    "\n",
    "ensure_pkgs()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 1) Local MCP servers (Search / Time)\n",
    "search_mcp_code = '''\\\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"SearchMCP\")\n",
    "\n",
    "try:\n",
    "    from duckduckgo_search import DDGS\n",
    "except Exception:\n",
    "    DDGS = None\n",
    "\n",
    "@mcp.tool()\n",
    "def web_search(query: str, max_results: int = 5) -> List[Dict]:\n",
    "    \"\"\"DuckDuckGo web search. Returns [{title, href, snippet}]\"\"\"\n",
    "    out = []\n",
    "    if DDGS is None:\n",
    "        return [{\"title\":\"[search unavailable]\",\"href\":\"\",\"snippet\":\"duckduckgo_search not installed or failed to import.\"}]\n",
    "    try:\n",
    "        with DDGS() as ddg:\n",
    "            for r in ddg.text(query, max_results=max(1, min(int(max_results), 10))):\n",
    "                out.append({\"title\": r.get(\"title\",\"\"), \"href\": r.get(\"href\",\"\"), \"snippet\": r.get(\"body\",\"\")})\n",
    "    except Exception as e:\n",
    "        out.append({\"title\":\"[search error]\", \"href\":\"\", \"snippet\":f\"{type(e).__name__}: {e}\"})\n",
    "    return out\n",
    "\n",
    "@mcp.tool()\n",
    "async def fetch(url: str, max_chars: int = 2000) -> Dict:\n",
    "    \"\"\"Fetch a URL and return {url, status, text[:max_chars]}\"\"\"\n",
    "    import httpx, re\n",
    "    try:\n",
    "        async with httpx.AsyncClient(follow_redirects=True, timeout=20) as client:\n",
    "            resp = await client.get(url)\n",
    "            text = re.sub(r\"\\\\s+\", \" \", resp.text)\n",
    "            return {\"url\": str(resp.url), \"status\": resp.status_code, \"text\": text[:max_chars]}\n",
    "    except Exception as e:\n",
    "        return {\"url\": url, \"status\": 0, \"text\": f\"{type(e).__name__}: {e}\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(\"stdio\")\n",
    "'''\n",
    "\n",
    "time_mcp_code = '''\\\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "except Exception:\n",
    "    ZoneInfo = None\n",
    "\n",
    "mcp = FastMCP(\"TimeMCP\")\n",
    "\n",
    "@mcp.tool()\n",
    "def now(tz: str = \"UTC\") -> Dict[str, Any]:\n",
    "    try:\n",
    "        z = ZoneInfo(tz) if ZoneInfo else None\n",
    "    except Exception:\n",
    "        z = None\n",
    "    if z is None:\n",
    "        from datetime import timezone\n",
    "        z = timezone.utc\n",
    "        tz = \"UTC\"\n",
    "    dt = datetime.now(z)\n",
    "    return {\"iso\": dt.isoformat(), \"date\": dt.strftime(\"%Y-%m-%d\"), \"time\": dt.strftime(\"%H:%M:%S\"), \"tz\": str(z)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(\"stdio\")\n",
    "'''\n",
    "\n",
    "ROOT.joinpath(\"search_mcp.py\").write_text(textwrap.dedent(search_mcp_code), encoding=\"utf-8\")\n",
    "ROOT.joinpath(\"time_mcp.py\").write_text(textwrap.dedent(time_mcp_code), encoding=\"utf-8\")\n",
    "print(\"Wrote servers to\", ROOT)\n",
    "\n",
    "# 2) Launch MCP servers\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "def mk_stdio(cmd, args, name):\n",
    "    return MCPServerStdio(\n",
    "        cmd, args=args,\n",
    "        env=BASE_ENV, cwd=str(ROOT),\n",
    "        timeout=180,\n",
    "        log_level=\"warn\",\n",
    "        log_handler=lambda e: None,   # set to print(...) for verbose logs\n",
    "    )\n",
    "\n",
    "time_server    = mk_stdio(sys.executable, [str(ROOT / \"time_mcp.py\")], \"time\")\n",
    "search_server  = mk_stdio(sys.executable, [str(ROOT / \"search_mcp.py\")], \"search\")\n",
    "\n",
    "async def probe(name, server):\n",
    "    try:\n",
    "        tools = await server.list_tools()\n",
    "        print(f\"‚úì {name} ready: {', '.join(t.name for t in tools)}\")\n",
    "        return server\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {name} disabled: {e}\")\n",
    "        return None\n",
    "\n",
    "servers = asyncio.run(asyncio.gather(\n",
    "    probe(\"time\", time_server),\n",
    "    probe(\"search\", search_server),\n",
    "))\n",
    "servers = [s for s in servers if s]\n",
    "\n",
    "# 3) Models & helpers\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "class Link(BaseModel):\n",
    "    title: str\n",
    "    url: str = \"\"\n",
    "    price: Optional[float] = None\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "class DayPlan(BaseModel):\n",
    "    date: str\n",
    "    summary: str = \"\"\n",
    "    activities: List[str] = Field(default_factory=list)\n",
    "\n",
    "class CostSummary(BaseModel):\n",
    "    currency: str = \"USD\"\n",
    "    flights: float = 0.0\n",
    "    hotels: float = 0.0\n",
    "    activities: float = 0.0\n",
    "    transit: float = 0.0\n",
    "    total: float = 0.0\n",
    "\n",
    "class TripPlan(BaseModel):\n",
    "    flights: List[Link] = Field(default_factory=list)\n",
    "    hotels: List[Link] = Field(default_factory=list)\n",
    "    day_by_day: List[DayPlan] = Field(default_factory=list)\n",
    "    transit_notes: str = \"\"\n",
    "    links: List[Link] = Field(default_factory=list)\n",
    "    cost_summary: CostSummary = Field(default_factory=CostSummary)\n",
    "\n",
    "class PlanSkeleton(BaseModel):\n",
    "    destination_city: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    day_by_day: List[DayPlan] = Field(default_factory=list)\n",
    "    notes: str = \"\"\n",
    "\n",
    "class DayIdeas(BaseModel):\n",
    "    date: str\n",
    "    ideas: List[Link] = Field(default_factory=list)\n",
    "\n",
    "class ResearchOutput(BaseModel):\n",
    "    days: List[DayIdeas] = Field(default_factory=list)\n",
    "    links: List[Link] = Field(default_factory=list)\n",
    "\n",
    "# 4) LLM provider pick\n",
    "MODEL = OpenAIModel(\"Qwen3-30B\", provider=provider)\n",
    "\n",
    "# 5) Utilities (dates, links) --------------------------------------------------\n",
    "def _valid_ymd(s: Optional[str]) -> bool:\n",
    "    if not isinstance(s, str): return False\n",
    "    try:\n",
    "        datetime.strptime(s.strip(), \"%Y-%m-%d\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def daterange(start_date: str, end_date: str) -> List[str]:\n",
    "    s = datetime.strptime(start_date, \"%Y-%m-%d\"); e = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    out, d = [], s\n",
    "    while d <= e:\n",
    "        out.append(d.strftime(\"%Y-%m-%d\")); d += timedelta(days=1)\n",
    "    return out\n",
    "\n",
    "from urllib.parse import quote\n",
    "def google_flights_link(origin: str, dest: str, depart: str, ret: str) -> str:\n",
    "    q = f\"Flights to {dest} from {origin} on {depart} through {ret}\"\n",
    "    return \"https://www.google.com/travel/flights/search?q=\" + quote(q)\n",
    "\n",
    "def booking_link(city: str, start: str, end: str) -> str:\n",
    "    return f\"https://www.booking.com/searchresults.html?ss={quote(city)}&checkin={start}&checkout={end}\"\n",
    "\n",
    "# 6) Dynamic place resolution (city or IATA)\n",
    "async def geocode_full(place: str) -> Optional[Dict[str, Any]]:\n",
    "    import httpx\n",
    "    async with httpx.AsyncClient(timeout=25) as client:\n",
    "        r = await client.get(\"https://geocoding-api.open-meteo.com/v1/search\", params={\"name\": place, \"count\": 1})\n",
    "        data = r.json()\n",
    "        res = data.get(\"results\") or []\n",
    "        if not res: return None\n",
    "        g = res[0]\n",
    "        return {\"name\": g.get(\"name\") or place, \"country\": g.get(\"country\",\"\"), \"lat\": g[\"latitude\"], \"lon\": g[\"longitude\"]}\n",
    "\n",
    "def looks_like_iata(s: str) -> bool:\n",
    "    return isinstance(s, str) and len(s) == 3 and s.isalpha() and s.upper() == s\n",
    "\n",
    "def _pick_city_from_text(text: str) -> Optional[str]:\n",
    "    for pat in [\n",
    "        r\"serv(?:es|ing)\\s+([A-Z][\\w\\- ]{2,40})\",\n",
    "        r\"near\\s+([A-Z][\\w\\- ]{2,40})\",\n",
    "        r\"([A-Z][\\w\\- ]{2,40})\\s+International Airport\",\n",
    "        r\"in\\s+([A-Z][\\w\\- ]{2,40})\\s*(?:,|\\.)\",\n",
    "    ]:\n",
    "        m = re.search(pat, text)\n",
    "        if m:\n",
    "            cand = re.sub(r\"[-‚Äì‚Äî|].*$\", \"\", m.group(1)).strip()\n",
    "            if 2 <= len(cand) <= 48: return cand\n",
    "    return None\n",
    "\n",
    "async def resolve_place(place: str) -> Tuple[str, Optional[Dict[str, Any]]]:\n",
    "    g = await geocode_full(place)\n",
    "    if g: return g[\"name\"], g\n",
    "    if looks_like_iata(place):\n",
    "        try:\n",
    "            from duckduckgo_search import DDGS\n",
    "            with DDGS() as ddg:\n",
    "                rs = list(ddg.text(f\"{place} IATA airport city\", max_results=6))\n",
    "        except Exception:\n",
    "            rs = []\n",
    "        cands = []\n",
    "        for r in rs:\n",
    "            blob = f\"{r.get('title','')} ‚Äî {r.get('body','')}\"\n",
    "            cand = _pick_city_from_text(blob)\n",
    "            if cand: cands.append(cand)\n",
    "        for cand in cands:\n",
    "            g2 = await geocode_full(cand)\n",
    "            if g2: return g2[\"name\"], g2\n",
    "    return place, None\n",
    "\n",
    "# 7) Agents (Planner & Researcher)\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "PLANNER = Agent[None, PlanSkeleton](\n",
    "    model=MODEL,\n",
    "    mcp_servers=servers,\n",
    "    system_prompt=(\n",
    "        \"You are the Planner. Given origin/destination city, dates (YYYY-MM-DD), budget and themes, \"\n",
    "        \"produce a concise skeleton itinerary (3‚Äì10 days). \"\n",
    "        \"Return PlanSkeleton {destination_city,start_date,end_date,day_by_day[]} with valid YYYY-MM-DD dates only.\"\n",
    "    ),\n",
    "    output_type=PlanSkeleton,\n",
    "    retries=2, output_retries=2,\n",
    ")\n",
    "\n",
    "RESEARCHER = Agent[None, ResearchOutput](\n",
    "    model=MODEL,\n",
    "    mcp_servers=servers,\n",
    "    system_prompt=(\n",
    "        \"You are the Researcher. For each day/date in the given city and themes, \"\n",
    "        \"use web_search and fetch to find 2‚Äì3 specific things to do (landmark, cafe, hike). \"\n",
    "        \"Return ResearchOutput with days[].ideas[] as Links(title,url,notes). Keep items relevant to the city.\"\n",
    "    ),\n",
    "    output_type=ResearchOutput,\n",
    "    retries=2, output_retries=2,\n",
    ")\n",
    "\n",
    "# 8) Weather helpers\n",
    "FORECAST_MAX_DAYS = 16\n",
    "\n",
    "async def wx_forecast_exact(lat: float, lon: float, start_ymd: str, end_ymd: str, tz: str = \"auto\") -> List[Dict[str, Any]]:\n",
    "    import httpx\n",
    "    params = {\n",
    "        \"latitude\": lat, \"longitude\": lon,\n",
    "        \"daily\": [\"temperature_2m_max\",\"temperature_2m_min\",\"precipitation_sum\"],\n",
    "        \"timezone\": tz, \"start_date\": start_ymd, \"end_date\": end_ymd,\n",
    "    }\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=25) as client:\n",
    "            d = (await client.get(\"https://api.open-meteo.com/v1/forecast\", params=params)).json().get(\"daily\", {})\n",
    "    except Exception:\n",
    "        return []\n",
    "    times = d.get(\"time\") or []; tmax = d.get(\"temperature_2m_max\") or []; tmin = d.get(\"temperature_2m_min\") or []; pmm = d.get(\"precipitation_sum\") or []\n",
    "    out = []\n",
    "    for i, day in enumerate(times):\n",
    "        try: out.append({\"date\": day, \"tmax\": float(tmax[i]), \"tmin\": float(tmin[i]), \"precip_mm\": float(pmm[i])})\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "async def wx_forecast_window(lat: float, lon: float, need_days_from_today: int, tz: str = \"auto\") -> List[Dict[str, Any]]:\n",
    "    import httpx\n",
    "    params = {\n",
    "        \"latitude\": lat, \"longitude\": lon,\n",
    "        \"daily\": [\"temperature_2m_max\",\"temperature_2m_min\",\"precipitation_sum\"],\n",
    "        \"timezone\": tz, \"forecast_days\": min(max(1, need_days_from_today), FORECAST_MAX_DAYS),\n",
    "    }\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=25) as client:\n",
    "            d = (await client.get(\"https://api.open-meteo.com/v1/forecast\", params=params)).json().get(\"daily\", {})\n",
    "    except Exception:\n",
    "        return []\n",
    "    times = d.get(\"time\") or []; tmax = d.get(\"temperature_2m_max\") or []; tmin = d.get(\"temperature_2m_min\") or []; pmm = d.get(\"precipitation_sum\") or []\n",
    "    out = []\n",
    "    for i, day in enumerate(times):\n",
    "        try: out.append({\"date\": day, \"tmax\": float(tmax[i]), \"tmin\": float(tmin[i]), \"precip_mm\": float(pmm[i])})\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "async def wx_era5_last_year(lat: float, lon: float, start_ymd: str, end_ymd: str, tz: str = \"auto\") -> List[Dict[str, Any]]:\n",
    "    import httpx\n",
    "    ly_start = (datetime.strptime(start_ymd, \"%Y-%m-%d\") - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "    ly_end   = (datetime.strptime(end_ymd,   \"%Y-%m-%d\") - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "    params = {\n",
    "        \"latitude\": lat, \"longitude\": lon,\n",
    "        \"daily\": [\"temperature_2m_max\",\"temperature_2m_min\",\"precipitation_sum\"],\n",
    "        \"timezone\": tz, \"start_date\": ly_start, \"end_date\": ly_end,\n",
    "    }\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=25) as client:\n",
    "            d = (await client.get(\"https://archive-api.open-meteo.com/v1/era5\", params=params)).json().get(\"daily\", {})\n",
    "    except Exception:\n",
    "        return []\n",
    "    times = d.get(\"time\") or []; tmax = d.get(\"temperature_2m_max\") or []; tmin = d.get(\"temperature_2m_min\") or []; pmm = d.get(\"precipitation_sum\") or []\n",
    "    out = []\n",
    "    for i, day in enumerate(times):\n",
    "        try: out.append({\"date\": day, \"tmax\": float(tmax[i]), \"tmin\": float(tmin[i]), \"precip_mm\": float(pmm[i])})\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "def wx_tip(tmin: float, tmax: float, pmm: float) -> str:\n",
    "    tip = \"Light layers.\"\n",
    "    if tmin < 12: tip = \"Pack a light jacket.\"\n",
    "    if pmm >= 3: tip += \" Chance of rain ‚Äî bring an umbrella.\"\n",
    "    return f\"Wx: {tmin:.0f}‚Äì{tmax:.0f}¬∞C, {pmm:.0f} mm. {tip}\"\n",
    "\n",
    "async def build_weather_map(lat: float, lon: float, start_ymd: str, end_ymd: str) -> Dict[str, Dict[str, float]]:\n",
    "    dates = daterange(start_ymd, end_ymd)\n",
    "    wx = await wx_forecast_exact(lat, lon, start_ymd, end_ymd)\n",
    "    wx_map = {r[\"date\"]: r for r in wx}\n",
    "    missing = [d for d in dates if d not in wx_map]\n",
    "    if missing:\n",
    "        today = datetime.utcnow().date()\n",
    "        days_ahead = (datetime.strptime(start_ymd, \"%Y-%m-%d\").date() - today).days\n",
    "        need_days = max(0, days_ahead) + len(dates)\n",
    "        if days_ahead <= FORECAST_MAX_DAYS:\n",
    "            window = await wx_forecast_window(lat, lon, need_days)\n",
    "            for r in window:\n",
    "                if r[\"date\"] in dates:\n",
    "                    wx_map[r[\"date\"]] = r\n",
    "            missing = [d for d in dates if d not in wx_map]\n",
    "    if missing:\n",
    "        ly = await wx_era5_last_year(lat, lon, start_ymd, end_ymd)\n",
    "        ly_map = {r[\"date\"]: r for r in ly}\n",
    "        for d in missing:\n",
    "            if d in ly_map: wx_map[d] = ly_map[d]\n",
    "        missing = [d for d in dates if d not in wx_map]\n",
    "    for d in missing:\n",
    "        wx_map[d] = {\"date\": d, \"tmax\": 24.0, \"tmin\": 18.0, \"precip_mm\": 1.0}\n",
    "    return wx_map\n",
    "\n",
    "# 9) Deterministic cost model\n",
    "def estimate_costs(distance_km: float, nights: int, days: int, budget_band: str = \"economy\") -> CostSummary:\n",
    "    if distance_km <= 0:\n",
    "        cpm = 0.10\n",
    "    elif distance_km > 6000:\n",
    "        cpm = 0.12\n",
    "    elif distance_km > 3000:\n",
    "        cpm = 0.10\n",
    "    else:\n",
    "        cpm = 0.07\n",
    "    flights = distance_km * cpm\n",
    "\n",
    "    band = (budget_band or \"economy\").lower()\n",
    "    nightly = 140 if band == \"economy\" else (200 if band == \"mid\" else 280)\n",
    "    hotels = nights * nightly\n",
    "\n",
    "    act_day = 35 if band == \"economy\" else (50 if band == \"mid\" else 80)\n",
    "    trn_day = 12 if band == \"economy\" else (18 if band == \"mid\" else 25)\n",
    "    activities = days * act_day\n",
    "    transit    = days * trn_day\n",
    "\n",
    "    total = flights + hotels + activities + transit\n",
    "    return CostSummary(currency=\"USD\",\n",
    "                       flights=round(flights, 2),\n",
    "                       hotels=round(hotels, 2),\n",
    "                       activities=round(activities, 2),\n",
    "                       transit=round(transit, 2),\n",
    "                       total=round(total, 2))\n",
    "\n",
    "# 10) Orchestrator\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "async def run_agent(agent: Agent, prompt: str):\n",
    "    async with agent.run_stream(prompt) as stream:\n",
    "        return await stream.get_output()\n",
    "\n",
    "def _relevant_to_city(link: Link, city: str) -> bool:\n",
    "    blob = f\"{link.title or ''} {link.notes or ''} {link.url or ''}\".lower()\n",
    "    return city.lower() in blob\n",
    "\n",
    "async def multi_agent_trip(origin_input: str, dest_input: str, start_date: str, end_date: str, budget: str, themes: str) -> TripPlan:\n",
    "    # Resolve places\n",
    "    origin_name, origin_geo = await resolve_place(origin_input)\n",
    "    dest_name, dest_geo     = await resolve_place(dest_input)\n",
    "\n",
    "    # 1) Planner\n",
    "    planner_prompt = (\n",
    "        f\"Origin: {origin_name}\\n\"\n",
    "        f\"Destination: {dest_name}\\n\"\n",
    "        f\"Dates: {start_date} to {end_date}\\n\"\n",
    "        f\"Budget: {budget}\\n\"\n",
    "        f\"Themes: {themes}\\n\"\n",
    "        \"Return a PlanSkeleton.\"\n",
    "    )\n",
    "    print(\"üß≠ Planner‚Ä¶\")\n",
    "    skel: PlanSkeleton = await run_agent(PLANNER, planner_prompt)\n",
    "\n",
    "    # Dates: sanitize + fill all days\n",
    "    safe_start = skel.start_date if _valid_ymd(skel.start_date) else start_date\n",
    "    safe_end   = skel.end_date   if _valid_ymd(skel.end_date)   else end_date\n",
    "    dates = daterange(safe_start, safe_end)  # inclusive\n",
    "    day_set = set(d.date for d in (skel.day_by_day or []) if _valid_ymd(d.date))\n",
    "    for d in dates:\n",
    "        if d not in day_set:\n",
    "            (skel.day_by_day).append(DayPlan(date=d, summary=f\"{dest_name} highlights\"))\n",
    "    skel.day_by_day = sorted(skel.day_by_day, key=lambda x: x.date)\n",
    "\n",
    "    # 2) Weather (full coverage)\n",
    "    print(\"‚õÖ Weather‚Ä¶\")\n",
    "    if dest_geo:\n",
    "        wx_map = await build_weather_map(dest_geo[\"lat\"], dest_geo[\"lon\"], safe_start, safe_end)\n",
    "    else:\n",
    "        wx_map = {d: {\"date\": d, \"tmax\": 24.0, \"tmin\": 18.0, \"precip_mm\": 1.0} for d in dates}\n",
    "\n",
    "    # 3) Research (no fallback ideas; keep only city-relevant items)\n",
    "    print(\"üîé Research‚Ä¶\")\n",
    "    research_prompt = (\n",
    "        f\"City: {dest_name}\\nDates: {', '.join(dates)}\\nThemes: {themes}\\n\"\n",
    "        \"Return ResearchOutput with 2‚Äì3 ideas per date (Links with title,url,notes).\"\n",
    "    )\n",
    "    research: ResearchOutput = await run_agent(RESEARCHER, research_prompt)\n",
    "    research.days = [d for d in (research.days or []) if _valid_ymd(d.date)]\n",
    "    ideas_map: Dict[str, List[Link]] = {}\n",
    "    for d in research.days:\n",
    "        filtered = [lnk for lnk in (d.ideas or []) if _relevant_to_city(lnk, dest_name)]\n",
    "        ideas_map[d.date] = filtered[:3]\n",
    "\n",
    "    # 4) Deterministic costs (non-zero)\n",
    "    def haversine_km(lat1, lon1, lat2, lon2):\n",
    "        if None in (lat1, lon1, lat2, lon2): return 0.0\n",
    "        R = 6371.0\n",
    "        p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "        dphi = math.radians(lat2 - lat1)\n",
    "        dlmb = math.radians(lon2 - lon1)\n",
    "        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "        return 2 * R * math.asin(math.sqrt(a))\n",
    "    lat1 = origin_geo[\"lat\"] if origin_geo else None\n",
    "    lon1 = origin_geo[\"lon\"] if origin_geo else None\n",
    "    lat2 = dest_geo[\"lat\"]   if dest_geo   else None\n",
    "    lon2 = dest_geo[\"lon\"]   if dest_geo   else None\n",
    "    distance_km = haversine_km(lat1, lon1, lat2, lon2)\n",
    "    nights = max(0, (datetime.strptime(safe_end, \"%Y-%m-%d\") - datetime.strptime(safe_start, \"%Y-%m-%d\")).days)\n",
    "    days = len(dates)\n",
    "    costs = estimate_costs(distance_km, nights, days, budget)\n",
    "\n",
    "    # 5) Links (Flights + Booking.com only) with computed prices\n",
    "    per_night = (costs.hotels / max(1, nights)) if nights else None\n",
    "    flights = [Link(\n",
    "        title=\"Google Flights\",\n",
    "        url=google_flights_link(origin_name, dest_name, safe_start, safe_end),\n",
    "        price=round(costs.flights, 0),\n",
    "        notes=\"Estimated roundtrip (distance √ó CPM); click for live fares\",\n",
    "    )]\n",
    "    hotels = [Link(\n",
    "        title=\"Booking.com\",\n",
    "        url=booking_link(dest_name, safe_start, safe_end),\n",
    "        price=round(costs.hotels, 0),\n",
    "        notes=f\"Estimated total for {nights} night(s)\" + (f\" (‚âà ${per_night:,.0f}/night)\" if per_night else \"\"),\n",
    "    )]\n",
    "\n",
    "    # 6) Merge day plans + weather tip (guaranteed for all days)\n",
    "    merged_days: List[DayPlan] = []\n",
    "    for d in skel.day_by_day:\n",
    "        if not _valid_ymd(d.date): continue\n",
    "        acts = list(d.activities or [])\n",
    "        for link in ideas_map.get(d.date, []):\n",
    "            acts.append(f\"{link.title} ‚Äî {link.url}\" if link.url else link.title)\n",
    "        w = wx_map.get(d.date)\n",
    "        if w:\n",
    "            acts.append(wx_tip(w[\"tmin\"], w[\"tmax\"], w[\"precip_mm\"]))\n",
    "        merged_days.append(DayPlan(date=d.date, summary=d.summary or f\"{dest_name} highlights\", activities=acts))\n",
    "\n",
    "    # NOTE: Fixed Local transit text per request (always Taipei wording)\n",
    "    fixed_transit_text = \"Consider local transit passes in Taipei. Compare airport rail vs rideshare.\"\n",
    "\n",
    "    return TripPlan(\n",
    "        flights=flights,\n",
    "        hotels=hotels,\n",
    "        day_by_day=merged_days,\n",
    "        transit_notes=fixed_transit_text,\n",
    "        links=[],\n",
    "        cost_summary=costs,\n",
    "    )\n",
    "\n",
    "def render_plan(plan: TripPlan) -> None:\n",
    "    def _links_table(items: List[Link], label: str) -> str:\n",
    "        if not items: return f\"_No {label.lower()} returned._\"\n",
    "        rows = [\"| # | Title | Price | Notes |\", \"|---:|---|---:|---|\"]\n",
    "        for i, l in enumerate(items, 1):\n",
    "            title = f\"[{l.title}]({l.url})\" if l.url else (l.title or \"\")\n",
    "            price = f\"${l.price:,.0f}\" if (l.price is not None) else \"\"\n",
    "            notes = l.notes or \"\"\n",
    "            rows.append(f\"| {i} | {title} | {price} | {notes} |\")\n",
    "        return \"\\n\".join(rows)\n",
    "\n",
    "    def _day_table(days: List[DayPlan]) -> str:\n",
    "        if not days: return \"_No day-by-day plan returned._\"\n",
    "        rows = [\"| Date | Plan |\", \"|---|---|\"]\n",
    "        for d in days:\n",
    "            bullets = \"<br>\".join(f\"‚Ä¢ {a}\" for a in (d.activities or []))\n",
    "            plan = (d.summary or \"\") + ((\"<br>\" + bullets) if bullets else \"\")\n",
    "            rows.append(f\"| {d.date} | {plan} |\")\n",
    "        return \"\\n\".join(rows)\n",
    "\n",
    "    parts = []\n",
    "    parts += [\"## ‚úàÔ∏è Flights\", _links_table(plan.flights, \"Flight links\")]\n",
    "    parts += [\"\\n\\n## üè® Hotels\", _links_table(plan.hotels, \"Hotel links\")]\n",
    "    parts += [\"\\n\\n## üìÖ Day-by-day\", _day_table(plan.day_by_day)]\n",
    "    parts += [\"\\n\\n## üöâ Local transit\", plan.transit_notes or \"_‚Äî_\"]\n",
    "    if plan.links:\n",
    "        parts += [\"\\n\\n## üîó Extra links\", _links_table(plan.links, \"Links\")]\n",
    "    cs = plan.cost_summary\n",
    "    parts += [\n",
    "        \"\\n\\n## üíµ Cost summary\",\n",
    "        f\"\"\"| Item | Cost ({cs.currency}) |\n",
    "|---|---:|\n",
    "| Flights | {cs.flights:,.0f} |\n",
    "| Hotels | {cs.hotels:,.0f} |\n",
    "| Activities | {cs.activities:,.0f} |\n",
    "| Transit | {cs.transit:,.0f} |\n",
    "| **Total** | **{cs.total:,.0f}** |\"\"\"\n",
    "    ]\n",
    "    display(Markdown(\"\\n\".join(parts)))\n",
    "\n",
    "# 11) Demo helper\n",
    "async def run_demo(\n",
    "    origin_airport: str = \"SFO\",\n",
    "    dest_city: str = \"NRT\",\n",
    "    start_date: str = \"2025-08-22\",\n",
    "    end_date: str = \"2025-08-31\",\n",
    "    budget: str = \"economy\",\n",
    "    themes: str = \"Manga, sushi, japanese culture, and historical buildings\",\n",
    "):\n",
    "    plan = await multi_agent_trip(origin_airport, dest_city, start_date, end_date, budget, themes)\n",
    "    render_plan(plan)\n",
    "\n",
    "print(\"üöÄ Running demo...\")\n",
    "asyncio.run(run_demo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: uncomment any to try\n",
    "asyncio.run(run_demo(\"SFO\", \"MSY\", \"2025-08-22\", \"2025-08-26\", \"economy\", \"Jazz, Soul Food, and Scenery\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy coding! If you encounter issues or have questions, don‚Äôt hesitate to ask or raise an issue on our [Github page](https://github.com/ROCm/gpuaidev)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step7\"></a>\n",
    "\n",
    "## Step 7: Challenge - Expand the Agent\n",
    "\n",
    "**Task:** The challenge for this workshop will be announced during the workshop. \n",
    "\n",
    "You can open a terminal and watch the GPU utilization by running this command:\n",
    "\n",
    "\n",
    "watch rocm-smi\n",
    "\n",
    "Let's set some environment variables for our server to use throughout this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the process of SGLang server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminate_process(server_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
